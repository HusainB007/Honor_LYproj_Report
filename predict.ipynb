{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mbhar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mbhar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\mbhar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"lap_times.csv\")\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data['lap_times_normalized'] = scaler.fit_transform(data['lap_time'].values.reshape(-1, 1))\n",
    "\n",
    "sequence_length = 3  \n",
    "\n",
    "X, y = [], []\n",
    "for i in range(len(data) - sequence_length):\n",
    "    X.append(data['lap_times_normalized'].values[i:i+sequence_length])\n",
    "    y.append(data['lap_times_normalized'].values[i+sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X = X.reshape(X.shape[0], sequence_length, 1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(50, input_shape=(sequence_length, 1)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\mbhar\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.0689 - val_loss: 0.5579\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0648 - val_loss: 0.5396\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0609 - val_loss: 0.5216\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0574 - val_loss: 0.5039\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0541 - val_loss: 0.4867\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0510 - val_loss: 0.4697\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0483 - val_loss: 0.4532\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0458 - val_loss: 0.4371\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0436 - val_loss: 0.4215\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0417 - val_loss: 0.4064\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0401 - val_loss: 0.3919\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0387 - val_loss: 0.3781\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0375 - val_loss: 0.3650\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0366 - val_loss: 0.3528\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0359 - val_loss: 0.3415\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0353 - val_loss: 0.3313\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0349 - val_loss: 0.3223\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0347 - val_loss: 0.3144\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0345 - val_loss: 0.3079\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0343 - val_loss: 0.3026\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0342 - val_loss: 0.2985\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0340 - val_loss: 0.2957\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0338 - val_loss: 0.2940\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0335 - val_loss: 0.2933\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0332 - val_loss: 0.2936\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0329 - val_loss: 0.2948\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0325 - val_loss: 0.2967\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0320 - val_loss: 0.2993\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0315 - val_loss: 0.3023\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0310 - val_loss: 0.3058\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0306 - val_loss: 0.3096\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0301 - val_loss: 0.3136\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0296 - val_loss: 0.3177\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0291 - val_loss: 0.3218\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.0287 - val_loss: 0.3259\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0283 - val_loss: 0.3299\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0279 - val_loss: 0.3338\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0275 - val_loss: 0.3374\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0271 - val_loss: 0.3408\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0268 - val_loss: 0.3438\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0264 - val_loss: 0.3466\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0261 - val_loss: 0.3490\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0258 - val_loss: 0.3511\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0254 - val_loss: 0.3529\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0251 - val_loss: 0.3543\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0247 - val_loss: 0.3554\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.0244 - val_loss: 0.3563\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0240 - val_loss: 0.3568\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0237 - val_loss: 0.3572\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0233 - val_loss: 0.3573\n",
      "Test Loss: 0.357300728559494\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 391ms/step\n",
      "Predicted lap time for lap number 14 : 91.9972\n"
     ]
    }
   ],
   "source": [
    "with open('lap_times.csv', \"r\", encoding=\"utf-8\", errors=\"ignore\") as scraped:\n",
    "    final_line = scraped.readlines()[-1]\n",
    "\n",
    "final_line_arr = final_line.split(',')\n",
    "last_lap_count = int(final_line_arr[1])\n",
    "\n",
    "new_lap_number = last_lap_count + 1\n",
    "\n",
    "\n",
    "new_lap_number_normalized = scaler.transform([[new_lap_number]])\n",
    "\n",
    "\n",
    "input_sequence = []\n",
    "for i in range(sequence_length, 0, -1):\n",
    "    input_sequence.append(new_lap_number_normalized - i)\n",
    "\n",
    "\n",
    "input_sequence = np.array(input_sequence).reshape(1, sequence_length, 1)\n",
    "\n",
    "\n",
    "predicted_lap_time_normalized = model.predict(input_sequence)\n",
    "\n",
    "predicted_lap_time = scaler.inverse_transform(predicted_lap_time_normalized)\n",
    "\n",
    "print(\"Predicted lap time for lap number\", new_lap_number, \":\", predicted_lap_time[0][0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
